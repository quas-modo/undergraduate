<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://quas-modo.github.io</id>
    <title>Carpe diem</title>
    <subtitle>pluck the day</subtitle>
    <icon>https://quas-modo.github.io/images/favicon.ico</icon>
    <link href="https://quas-modo.github.io" />
    <author>
      <name>quas-modo</name>
    </author>
    <updated>2023-09-27T09:35:36.000Z</updated>
    <entry>
        <id>https://quas-modo.github.io/2023/09/27/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E4%BB%A5%E4%BA%BA%E4%B8%BA%E6%9C%AC%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%9A%E5%8F%AF%E9%9D%A0%E3%80%81%E5%AE%89%E5%85%A8%E3%80%81%E5%8F%AF%E4%BF%A1/</id>
        <title>论文阅读：以人为本的人工智能：可靠、安全、可信</title>
        <link rel="alternate" href="https://quas-modo.github.io/2023/09/27/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E4%BB%A5%E4%BA%BA%E4%B8%BA%E6%9C%AC%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%9A%E5%8F%AF%E9%9D%A0%E3%80%81%E5%AE%89%E5%85%A8%E3%80%81%E5%8F%AF%E4%BF%A1/"/>
        <content type="html">&lt;p&gt;总结自论文 Human-Centered Artificial Intelligence: Reliable, Safe &amp;amp; Trustworthy&lt;/p&gt;
&lt;p&gt;&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;论文阅读好用的工具推荐&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#论文阅读好用的工具推荐&#34;&gt;#&lt;/a&gt; 论文阅读好用的工具推荐&lt;/h2&gt;
&lt;p&gt;DeepL，声称是全世界最流畅的翻译软件，确实对得起自己的名号，学术论文翻出来基本上是一个可读可用的状态，中英文对照着看很舒服&lt;/p&gt;
&lt;p&gt;chatPDF，输入 PDF，然后可以根据论文内容进行问答，本质上应该是把论文作为输入给 gpt 了，作为一个智能问答和智能搜索的工具还挺好用的&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#摘要&#34;&gt;#&lt;/a&gt; 摘要&lt;/h2&gt;
&lt;p&gt;经过精心设计的技术可以提供高水平的人类控制和高水平的计算机自动化，从而提高人 类的绩效，使其得到更广泛的应用。以人为本的人工智能（HCAI）框架阐明了如何&lt;br /&gt;
（1 ）设计高水平的人类控制和高水平的计算机自动化，以提高人类的绩效&lt;br /&gt;
（2）了解在哪些情况下需要完全的人类控制或完全的计算机控制&lt;br /&gt;
 (3) 避免过度人为控制或过度计算机控制的危险。&lt;br /&gt;
HCAI 方法更有可能产生可靠、安全和可信（RST）的设计。实现这些目标将极大地提高人类的绩效，同时支持人类的自我效能感、主人翁精神、创造力和责任感。&lt;/p&gt;
&lt;h2 id=&#34;文章架构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#文章架构&#34;&gt;#&lt;/a&gt; 文章架构&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;介绍&lt;/li&gt;
&lt;li&gt;可靠、安全、可信（RST）的系统策略&lt;/li&gt;
&lt;li&gt;以人为本的 RST 系统人工智能（阐述了新颖的二维 HCAI 框架， 描述了不同的设计目标以及实现高水平人类控制和高水平自动化的途径）&lt;/li&gt;
&lt;li&gt;设计原则和实例&lt;/li&gt;
&lt;li&gt;摘要、局限性和结论&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;文章主要内容梳理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#文章主要内容梳理&#34;&gt;#&lt;/a&gt; 文章主要内容梳理&lt;/h2&gt;
&lt;p&gt;理解这篇论文，最重要的就是这几个短语&lt;br /&gt;
&lt;strong&gt; HCAI 二维框架&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;高水平的人类控制和高水平的计算机自动化&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;可靠、安全和可信（RST）&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;介绍&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#介绍&#34;&gt;#&lt;/a&gt; 介绍&lt;/h3&gt;
&lt;p&gt;首先，这篇论文提出了一个 “以人为中心的人工智能 HCAI” 的二维框架。那么这有个前提（也是这篇论文批判的靶子）是，之前的框架是一维的，也就是说，自动化程度的提高必须以降低人类控制为代价，尽管有许多批评意见，自动化 / 自主化的一维水平仍然具有广泛的影响力。例如，美国汽车工程师学会在其自动驾驶汽车的六个 自主级别中采用了不必要的权衡。过度自主化造成的重大灾难包括伊拉克战争期间爱国者导弹系统击落两架友军飞机（ Blackhurst 等人，2004 年）和波音 737 MAX 坠毁事件（Nicas 等人，2019 年）。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://quasdo.oss-cn-hangzhou.aliyuncs.com/img/image-20230927173111718.png&#34; alt=&#34;image-20230927173111718&#34; /&gt;&lt;/p&gt;
&lt;p&gt;那么既然，一维框架有这么多的危害，因此这篇论文提出了二维框架，也就是高水平的人类控制和高水平的计算机自动化是可以共存且相互促进的，而不是一种敌对的状态。所以我们要更加重视以人为本的设计，这更能够建立可靠、安全、值得信赖的系统。&lt;/p&gt;
&lt;h3 id=&#34;可靠-安全-值得信赖的系统&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#可靠-安全-值得信赖的系统&#34;&gt;#&lt;/a&gt; 可靠、安全、值得信赖的系统&lt;/h3&gt;
&lt;p&gt;为什么要这样的系统？&lt;br /&gt;
电梯、 摄像头、家用电器、电动轮椅或医疗设备等成熟技术的用户都知道，这些设备是值得信 赖、可靠和安全的。&lt;br /&gt;
设计精良的自动化设备可以确 保对人类进行更精细的控制，例如外科手术机器人可以让外科医生在难以触及的器官上 进行更精确的切口。&lt;/p&gt;
&lt;p&gt;这三个词具体是什么意思？&lt;/p&gt;
&lt;h5 id=&#34;支持可靠性的技术实践&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#支持可靠性的技术实践&#34;&gt;#&lt;/a&gt; 支持可靠性的技术实践&lt;/h5&gt;
&lt;p&gt;可靠（Modarres 等人，2016 年）的系统来自适当的技术实践，这些实践支持人类责任（ 加拿大政府，2019 年）、公平（O&#39;Neil，2016 年）和可解释性（Du、Liu 和 Hu，2019 年 ）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;审查故障和险情的审计跟踪和分析工具&lt;/li&gt;
&lt;li&gt;被广泛接受用于验证和确认的基准测试&lt;/li&gt;
&lt;li&gt;不断审查数据质量和偏差测试，以应对不断变化的使用环境&lt;/li&gt;
&lt;li&gt;设计战略，在各利益相关群体之间建立信任&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;创建安全文化的管理策略&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建安全文化的管理策略&#34;&gt;#&lt;/a&gt; 创建安全文化的管理策略&lt;/h5&gt;
&lt;p&gt;安全文化（Guldenmund，2000 年；Berry 等人，2016 年）是通过开放式管理策略培养起来 的，例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;领导层对安全的承诺&lt;/li&gt;
&lt;li&gt;邀请报告组织内部的问题&lt;/li&gt;
&lt;li&gt;内部审查委员会对故障和险情进行审查&lt;/li&gt;
&lt;li&gt;关于未能促进讨论的公开报告&lt;/li&gt;
&lt;li&gt;未来计划和过去做法的内部监督委员会&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;支持信任的独立监督结构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#支持信任的独立监督结构&#34;&gt;#&lt;/a&gt; 支持信任的独立监督结构&lt;/h5&gt;
&lt;p&gt;福山将重点放在社会信任上， &amp;quot;在一个社区内，社区成员基于共同的规范，采取有规律、诚实和合作的行为&amp;quot;。他的定义以社区为基础，通过依靠受尊重的独立监督结构来提高信任度。包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有能力建设、运营和维护技术的公司&lt;/li&gt;
&lt;li&gt;制定有效的自愿准则和标准的专业组织（国际标准组织、电气和电子工程师 学会、机器人工业协会）&lt;/li&gt;
&lt;li&gt;以促进创新的方式进行监管的政府机构 (美国食品和药物管理局、联邦航空管理局、国家公路交通安全管理局）&lt;/li&gt;
&lt;li&gt;对公司和产品进行认证的非政府组织（保险商实验室、更好的商业局 、消费者联盟）&lt;/li&gt;
&lt;li&gt;在审计公司方面具有显著价值的会计师事务所（毕马威会 -8- 计师事务所、安永会计师事务所、德勤会计师事务所、 普华永道会计师事务所）&lt;/li&gt;
&lt;li&gt;保险公司通过对失败进行赔偿来促进信任。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;以人为本的-rst-系统人工智能&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#以人为本的-rst-系统人工智能&#34;&gt;#&lt;/a&gt; 以人为本的 RST 系统人工智能&lt;/h3&gt;
&lt;p&gt;理想的目标通常是（但不总是）位于右上象限。大多数 RST 系统都位于右侧。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://quasdo.oss-cn-hangzhou.aliyuncs.com/img/image-20230927173244438.png&#34; alt=&#34;image-20230927173244438&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;右下象限&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#右下象限&#34;&gt;#&lt;/a&gt; 右下象限&lt;/h4&gt;
&lt;p&gt;右下象限适用于&lt;strong&gt;相对易懂和可预测&lt;/strong&gt;的任务，如汽车自动变速器或普通公路上的防滑控制。&lt;br /&gt;
右下象限（图 3）自动化程度高，人为控制程度低，是需要&lt;strong&gt;快速行动&lt;/strong&gt;的计算机自主系统的 所在地，例如安全气囊展开、防抱死制动器、心脏起搏器、植入式去纤颤器或防御武器系统。在这些应用中，人类没有时间进行干预或控制。由于故障的代价如此之高，这些 应用需要极其谨慎的设计、广泛的测试和大规模使用期间的监控，以完善设计。经过验 证的有效设计可以成为自动化程度更高、人工监控更少的 RST 系统。&lt;/p&gt;
&lt;h4 id=&#34;右上象限&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#右上象限&#34;&gt;#&lt;/a&gt; 右上象限&lt;/h4&gt;
&lt;p&gt;而对于理解不深、复杂且使用环境各异的任务，则需要使用右上象限。这些任务涉及创造性决策，因此目前处于研究前沿。随着使用环境的标准化（如电梯井），这些任务可以在更 大程度上由计算机控制，实现高度自动化。&lt;/p&gt;
&lt;h4 id=&#34;左上象限&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#左上象限&#34;&gt;#&lt;/a&gt; 左上象限&lt;/h4&gt;
&lt;p&gt;左上象限高度人为控制，自动化程度较高，是人类自主的家园，在这里，人们希望通过人类的掌握来培养能力、自由探索和创造力。例如，骑自行车、弹钢琴、烘焙或与孩子玩耍  在这些活动中，人类一般都希望从寻求掌握、提高技能和全身心投入中获得快乐。他们 可能会选择使用基于计算机的系统进行培训、复习或指导，但许多人希望通过独立行动 来掌握技能，从而建立自我效能感。在这些行动中，目标在于行动和行动带来的个人满 足感，以及创造性探索的潜力&lt;/p&gt;
&lt;h4 id=&#34;左下象限&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#左下象限&#34;&gt;#&lt;/a&gt; 左下象限&lt;/h4&gt;
&lt;p&gt;左下象限是钟表或捕鼠器等简单装置以及地雷等致命装置的家园。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://quasdo.oss-cn-hangzhou.aliyuncs.com/img/image-20230927173252418.png&#34; alt=&#34;image-20230927173252418&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;边缘情况&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#边缘情况&#34;&gt;#&lt;/a&gt; 边缘情况&lt;/h4&gt;
&lt;p&gt;最右边（图 4）是过度自动化区域，这里的危险来自于以下设计波音 737 MAX 的 MCAS 系统。除了一个攻击角度传感器的单点故障问题外，设计人员还认为他们的自主系统不会出现故障。因此，用户手册中没有说明它的存在，飞行员也没有接受过如何切换到手动超控的培训 。IBM 人工智能指南》明智地警告说，&amp;quot;难以察觉的人工智能不是合乎道德的人工智能&amp;quot;&lt;/p&gt;
&lt;p&gt;过度的人为控制也会使人们犯下致命的错误。自动化控制、人为因素承受能力和预防灾难性故障是实现以下目标的既定战略减少 &amp;quot;人为失误&amp;quot; 造成的致命后果，这些失误应被视为设计失误。&lt;br /&gt;
防止过度人为控制的其他方法包括基于汽车的点火互锁装置，该装置可进行呼气酒精测试，以防止呼气中含有大量酒精的驾驶员打开汽车。正轨列车控制系统限制工程师在弯道或终点站区域高速行驶。&lt;br /&gt;
车厂提供防抱死制动系统和巡航控制系统、车道控制、泊车 辅助、自动制动和防碰撞等功能。&lt;/p&gt;
&lt;h3 id=&#34;普罗米修斯原则&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#普罗米修斯原则&#34;&gt;#&lt;/a&gt; 普罗米修斯原则&lt;/h3&gt;
&lt;p&gt;AI + IA，人工智能和增强智能结合，在自动化和用户控制之间保持平衡。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一致的界面，允许用户形成、表达和修改意图&lt;/li&gt;
&lt;li&gt;连续可视化显示感兴趣的物体和动作&lt;/li&gt;
&lt;li&gt;快速、渐进和可逆的行动&lt;/li&gt;
&lt;li&gt;翔实的反馈信息，以确认用户的每个操作&lt;/li&gt;
&lt;li&gt;显示状态的进度指标&lt;/li&gt;
&lt;li&gt;完成报告，以确认完成情况。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;例子病人自控镇痛装置pca&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#例子病人自控镇痛装置pca&#34;&gt;#&lt;/a&gt; 例子 —— 病人自控镇痛装置（PCA）&lt;/h3&gt;
&lt;p&gt;&lt;img data-src=&#34;https://quasdo.oss-cn-hangzhou.aliyuncs.com/img/image-20230927173313136.png&#34; alt=&#34;image-20230927173313136&#34; /&gt;&lt;/p&gt;
&lt;p&gt;病人自控镇痛（PCA）装置（图 6）允许手术后、重症癌症或临终关怀病人选择镇 痛药物的用量和频率。年轻和年老的病人都会遇到危险和问题，但如果设计和管理得当 ，患者自控镇痛装置可以安全有效地控制疼痛（Macintyre，2001 年）。&lt;br /&gt;
用于左下象限的简单吗啡点滴袋（自动化程度低，人工控制程度低）将定期提供固定剂量的止痛药物。&lt;br /&gt;
针对右下象限的自动化程度较高的设计（自动化程度较高，但人工控制程度较低）将提供机器选择的剂量，该剂量可根据一天中的时间、活动以及身体体征传感器的数据而变 化，尽管这些数据并不能评估感知到的疼痛。&lt;br /&gt;
左上象限以人为本的设计（较高的人为控制，较低的自动化程度）允许患者按下扳机来 控制止痛药物的剂量、频率和总量。然而，必须通过联锁来控制过量用药的危险，防止频繁用药，锁定时间一般为 6-10 分钟，总剂量限制为 1-4 小时。&lt;br /&gt;
最后，右上象限的 RST 设计将允许用户扣动扳机以获得更多止痛药，但会使用传感器和机器学习，根据患者和疾病变量选择适当的剂量，同时防止用药过量。患者将能够获得有关限制止痛药剂量为 何重要的信息，并获得有关如何操作 PCA 设备的解释。&lt;br /&gt;
RST 的设计将包括一个医院控制中心，用于监控数百个 PCA 设备的使用情况，以确保安全操作，处理电源或其他故障， 查看审计跟踪，并收集数据以改进下一代 PCA 设备。&lt;/p&gt;
&lt;h3 id=&#34;例子洗碗机-洗衣机-烤箱&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#例子洗碗机-洗衣机-烤箱&#34;&gt;#&lt;/a&gt; 例子 —— 洗碗机、洗衣机、烤箱&lt;/h3&gt;
&lt;p&gt;洗碗机、洗衣机 / 干衣机和烤箱等家用电器允许用户选择设置，说明他们想要什 么，然后将控制权交给传感器和定时器来管理整个过程。如果设计得当，这些机器就能 为用户提供可理解和可预测的控制，让他们能够通过控制来表达自己的意图，比如让他 们停止洗碗机以放入另一个盘子，或者将烤鸡肉从烘烤改为炙烤。这些自动化功能让用 户能够更好地控制这些设备，确保他们得到想要的东西。&lt;/p&gt;
&lt;h3 id=&#34;结论&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#结论&#34;&gt;#&lt;/a&gt; 结论&lt;/h3&gt;
&lt;p&gt;HCAI 框架将人类控制与计算机自动化问题分开，明确指出通过良好的设计可以实现高水 平的人类控制和高水平的自动化。设计决策可让人类操作员清楚地了解机器状态和他们 的选择，并以错误的后果和可逆性等问题为指导。 精心设计的自动化系统可在适当的情况下保留人为控制，从而提高性能并实现创造性的改进。&lt;/p&gt;
</content>
        <category term="论文阅读" scheme="https://quas-modo.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" />
        <category term="人机交互" scheme="https://quas-modo.github.io/tags/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92/" />
        <updated>2023-09-27T09:35:36.000Z</updated>
    </entry>
</feed>
